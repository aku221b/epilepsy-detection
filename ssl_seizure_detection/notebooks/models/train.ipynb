{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'data_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Model parameters\u001b[39;00m\n\u001b[1;32m     10\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_node_features\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m9\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_edge_features\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m }\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatient_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdummy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msupervised\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtiming\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m          \u001b[49m\u001b[43mclassify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassify\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhead\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatetime_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dict_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransfer_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m          \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTest_Bay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.002\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'data_path'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from train import train\n",
    "import torch\n",
    "\n",
    "data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\jh101\\supervised\"\n",
    "logdir = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\test\"\n",
    "\n",
    "# Model parameters\n",
    "config = {\n",
    "    \"num_node_features\": 9,\n",
    "    \"num_edge_features\": 3,\n",
    "    \"hidden_channels\": [32, 16, 16],\n",
    "    \"batch_norm\": True,\n",
    "    \"classify\": \"binary\",\n",
    "    \"head\": \"linear\",\n",
    "}\n",
    "\n",
    "\n",
    "train(data_path=data_path, logdir=logdir, patient_id=\"dummy\", epochs=40, config=config, data_size=0.5, val_ratio=0.2, test_ratio=0.1, \n",
    "          batch_size=32, num_workers=4, lr=[1e-3, 0.02], weight_decay=1e-3, model_id=\"supervised\", timing=True, \n",
    "          classify=config[\"classify\"], head=config[\"head\"], dropout=False, datetime_id=None, run_type=\"all\", requires_grad=True,\n",
    "          model_path=None, model_dict_path=None, transfer_id=None, train_ratio=None, loss_config=None,\n",
    "          project_id=\"Test_Bay\", patience = 20, eta_min=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative Positioning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\xmoot\\Desktop\\VSCode\\ssl-seizure-detection\\notebooks\\wandb\\run-20231210_233851-a6j7juud</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/a6j7juud' target=\"_blank\">dummy_relative_positioning_None_all</a></strong> to <a href='https://wandb.ai/xmootoo/ssl-seizure-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xmootoo/ssl-seizure-detection' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/a6j7juud' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection/runs/a6j7juud</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "None\n",
      "Total number of examples in dataset: 50.\n",
      "Total number of examples used: 50.\n",
      "Number of training examples: 35. Number of training batches: 2.\n",
      "Number of validation examples: 10. Number of validation batches: 1.\n",
      "Number of test examples: 5. Number of test batches: 1.\n",
      "Time elapsed after 100 batches (training): 3.91554856300354\n",
      "Time elapsed after 100 batches (evaluation): 3.7740020751953125\n",
      "Epoch: 1, Train Loss: 0.6954334378242493, Train Accuracy: 54.285714285714285, Validation Loss: 0.6861836314201355, Validation Accuracy: 60.0\n",
      "Time elapsed after 100 batches (evaluation): 3.752501964569092\n",
      "Training complete. Test Loss: 0.6738660931587219. Test Accuracy: 60.0.\n",
      "Training complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁</td></tr><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr><tr><td>Training Accuracy</td><td>▁</td></tr><tr><td>Training Loss</td><td>▁</td></tr><tr><td>Validation Accuracy</td><td>▁</td></tr><tr><td>Validation Loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1</td></tr><tr><td>Test Accuracy</td><td>60.0</td></tr><tr><td>Test Loss</td><td>0.67387</td></tr><tr><td>Training Accuracy</td><td>54.28571</td></tr><tr><td>Training Loss</td><td>0.69543</td></tr><tr><td>Validation Accuracy</td><td>60.0</td></tr><tr><td>Validation Loss</td><td>0.68618</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dummy_relative_positioning_None_all</strong> at: <a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/a6j7juud' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection/runs/a6j7juud</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231210_233851-a6j7juud\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mac\n",
    "# data_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_pyg/jh101/relative_positioning/12s_90s\"\n",
    "# logdir = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/models/jh101\"\n",
    "\n",
    "# PC\n",
    "data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\jh101\\relative_positioning\"\n",
    "logdir = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\test\"\n",
    "\n",
    "# Training parameters\n",
    "patient_id = \"dummy\"\n",
    "epochs = 1\n",
    "model_id = \"relative_positioning\"\n",
    "\n",
    "config = {\n",
    "    \"num_node_features\": 9,\n",
    "    \"num_edge_features\": 3,\n",
    "    \"hidden_channels\": [64, 32, 64, 128, 256],\n",
    "    }\n",
    "data_size=50\n",
    "\n",
    "train(data_path, logdir, patient_id, epochs, config, data_size=data_size, val_ratio=0.2, test_ratio=0.1, \n",
    "          batch_size=32, num_workers=4, lr=1e-3, weight_decay=1e-3, model_id=\"relative_positioning\", timing=True, \n",
    "          classify=\"binary\", head=\"linear\", dropout=True, datetime_id=None, run_type=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Shuffling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\xmoot\\Desktop\\VSCode\\ssl-seizure-detection\\notebooks\\wandb\\run-20231210_233758-d40tlcg7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/d40tlcg7' target=\"_blank\">dummy_temporal_shuffling_None_all</a></strong> to <a href='https://wandb.ai/xmootoo/ssl-seizure-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xmootoo/ssl-seizure-detection' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/d40tlcg7' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection/runs/d40tlcg7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "None\n",
      "Total number of examples in dataset: 1000.\n",
      "Total number of examples used: 1000.\n",
      "Number of training examples: 100. Number of training batches: 4.\n",
      "Number of validation examples: 800. Number of validation batches: 25.\n",
      "Number of test examples: 100. Number of test batches: 4.\n",
      "Time elapsed after 100 batches (training): 3.8819971084594727\n",
      "Time elapsed after 100 batches (evaluation): 13.195449829101562\n",
      "Epoch: 1, Train Loss: 0.6687844693660736, Train Accuracy: 52.0, Validation Loss: 0.6969042730331421, Validation Accuracy: 51.25\n",
      "Time elapsed after 100 batches (evaluation): 3.9409987926483154\n",
      "Training complete. Test Loss: 0.712275430560112. Test Accuracy: 52.0.\n",
      "Training complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁</td></tr><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr><tr><td>Training Accuracy</td><td>▁</td></tr><tr><td>Training Loss</td><td>▁</td></tr><tr><td>Validation Accuracy</td><td>▁</td></tr><tr><td>Validation Loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1</td></tr><tr><td>Test Accuracy</td><td>52.0</td></tr><tr><td>Test Loss</td><td>0.71228</td></tr><tr><td>Training Accuracy</td><td>52.0</td></tr><tr><td>Training Loss</td><td>0.66878</td></tr><tr><td>Validation Accuracy</td><td>51.25</td></tr><tr><td>Validation Loss</td><td>0.6969</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dummy_temporal_shuffling_None_all</strong> at: <a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/d40tlcg7' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection/runs/d40tlcg7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231210_233758-d40tlcg7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mac\n",
    "# data_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_pyg/jh101/temporal_shuffling/12s_90s\"\n",
    "# logdir = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/models/jh101\"\n",
    "\n",
    "# PC\n",
    "data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\jh101\\temporal_shuffling\"\n",
    "logdir = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\test\"\n",
    "\n",
    "# Training parameters\n",
    "patient_id = \"dummy\"\n",
    "epochs = 1\n",
    "model_id = \"temporal_shuffling\"\n",
    "\n",
    "config = {\n",
    "    \"num_node_features\": 9,\n",
    "    \"num_edge_features\": 3,\n",
    "    \"hidden_channels\": [64, 32, 64, 128, 256],\n",
    "}\n",
    "data_size = 1000\n",
    "\n",
    "train(data_path, logdir, patient_id, epochs, config, data_size=data_size, val_ratio=0.8, test_ratio=0.1, \n",
    "          batch_size=32, num_workers=4, lr=1e-3, weight_decay=1e-3, model_id=\"temporal_shuffling\", timing=True, \n",
    "          classify=\"binary\", head=\"linear\", dropout=True, datetime_id=None, run_type=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Learning\n",
    "Relative Positioning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\xmoot\\Desktop\\VSCode\\ssl-seizure-detection\\notebooks\\wandb\\run-20231210_233710-o6mfr48i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/o6mfr48i' target=\"_blank\">dummy_downstream1_None_all</a></strong> to <a href='https://wandb.ai/xmootoo/ssl-seizure-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xmootoo/ssl-seizure-detection' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/o6mfr48i' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection/runs/o6mfr48i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "None\n",
      "Total number of examples in dataset: 114.\n",
      "Total number of examples used: 114.\n",
      "Number of training examples: 81. Number of training batches: 3.\n",
      "Number of validation examples: 22. Number of validation batches: 1.\n",
      "Number of test examples: 11. Number of test batches: 1.\n",
      "Time elapsed after 100 batches (training): 3.9454996585845947\n",
      "Time elapsed after 100 batches (evaluation): 2.8545029163360596\n",
      "Epoch: 1, Train Loss: 3.4345645904541016, Train Accuracy: 49.382716049382715, Validation Loss: 1.4942657947540283, Validation Accuracy: 59.09090909090909\n",
      "Time elapsed after 100 batches (training): 3.860501766204834\n",
      "Time elapsed after 100 batches (evaluation): 3.0605010986328125\n",
      "Epoch: 2, Train Loss: 2.4021639029184976, Train Accuracy: 40.74074074074074, Validation Loss: 1.0440126657485962, Validation Accuracy: 63.63636363636363\n",
      "Time elapsed after 100 batches (evaluation): 2.7449991703033447\n",
      "Training complete. Test Loss: 1.3754545450210571. Test Accuracy: 54.54545454545455.\n",
      "Training complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁█</td></tr><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr><tr><td>Training Accuracy</td><td>█▁</td></tr><tr><td>Training Loss</td><td>█▁</td></tr><tr><td>Validation Accuracy</td><td>▁█</td></tr><tr><td>Validation Loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>2</td></tr><tr><td>Test Accuracy</td><td>54.54545</td></tr><tr><td>Test Loss</td><td>1.37545</td></tr><tr><td>Training Accuracy</td><td>40.74074</td></tr><tr><td>Training Loss</td><td>2.40216</td></tr><tr><td>Validation Accuracy</td><td>63.63636</td></tr><tr><td>Validation Loss</td><td>1.04401</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dummy_downstream1_None_all</strong> at: <a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/o6mfr48i' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection/runs/o6mfr48i</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231210_233710-o6mfr48i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from train import train\n",
    "\n",
    "# Mac\n",
    "# data_path = \"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\jh101\\supervised\"\n",
    "# logdir = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/models/downstream\"\n",
    "# model_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/models/jh101/model/relative_positioning.pth\"\n",
    "# model_dict_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/models/jh101/model/relative_positioning_state_dict.pth\"\n",
    "\n",
    "# PC\n",
    "data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\jh101\\supervised\"\n",
    "logdir = r\"C:\\Users\\xmoot\\Desktop\\Models\\ssl-seizure-detection\\jh101\"\n",
    "model_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\test\\model\\relative_positioning.pth\"\n",
    "model_dict_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\test\\model\\relative_positioning_state_dict.pth\"\n",
    "\n",
    "\n",
    "# Model configurations\n",
    "model_id1 = \"downstream1\"\n",
    "config1 = {\n",
    "        \"hidden_channels\": [64, 64, 32],\n",
    "        \"dropout\": 0.1,\n",
    "}\n",
    "\n",
    "\n",
    "model_id2 = \"downstream2\"\n",
    "config2 = {\n",
    "        \"hidden_channels\": 32,\n",
    "        \"dropout\": 0.1,\n",
    "}\n",
    "\n",
    "\n",
    "train(data_path, logdir, patient_id=\"dummy\", epochs=2, config=config1, data_size=0.05, val_ratio=0.2, test_ratio=0.1, \n",
    "          batch_size=32, num_workers=4, lr=1e-3, weight_decay=1e-3, model_id=model_id1, timing=True, \n",
    "          classify=\"multiclass\", head=\"linear\", dropout=True, datetime_id=None, run_type=\"all\", \n",
    "          frozen=False, model_path=model_path, model_dict_path=model_dict_path, transfer_id=\"relative_positioning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporal shuffling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\xmoot\\Desktop\\VSCode\\ssl-seizure-detection\\notebooks\\wandb\\run-20231210_233621-eyw68ffi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/eyw68ffi' target=\"_blank\">dummy_downstream1_None_all</a></strong> to <a href='https://wandb.ai/xmootoo/ssl-seizure-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xmootoo/ssl-seizure-detection' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/eyw68ffi' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection/runs/eyw68ffi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "None\n",
      "Total number of examples in dataset: 114.\n",
      "Total number of examples used: 114.\n",
      "Number of training examples: 81. Number of training batches: 3.\n",
      "Number of validation examples: 22. Number of validation batches: 1.\n",
      "Number of test examples: 11. Number of test batches: 1.\n",
      "Time elapsed after 100 batches (training): 4.502000570297241\n",
      "Time elapsed after 100 batches (evaluation): 3.020418882369995\n",
      "Epoch: 1, Train Loss: 1.9184710780779521, Train Accuracy: 55.55555555555556, Validation Loss: 0.37488746643066406, Validation Accuracy: 90.9090909090909\n",
      "Time elapsed after 100 batches (training): 3.985499382019043\n",
      "Time elapsed after 100 batches (evaluation): 3.043998956680298\n",
      "Epoch: 2, Train Loss: 0.5761664907137553, Train Accuracy: 76.54320987654322, Validation Loss: 0.3191727101802826, Validation Accuracy: 90.9090909090909\n",
      "Time elapsed after 100 batches (evaluation): 2.9595015048980713\n",
      "Training complete. Test Loss: 0.2639373540878296. Test Accuracy: 90.9090909090909.\n",
      "Training complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁█</td></tr><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Loss</td><td>▁</td></tr><tr><td>Training Accuracy</td><td>▁█</td></tr><tr><td>Training Loss</td><td>█▁</td></tr><tr><td>Validation Accuracy</td><td>▁▁</td></tr><tr><td>Validation Loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>2</td></tr><tr><td>Test Accuracy</td><td>90.90909</td></tr><tr><td>Test Loss</td><td>0.26394</td></tr><tr><td>Training Accuracy</td><td>76.54321</td></tr><tr><td>Training Loss</td><td>0.57617</td></tr><tr><td>Validation Accuracy</td><td>90.90909</td></tr><tr><td>Validation Loss</td><td>0.31917</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dummy_downstream1_None_all</strong> at: <a href='https://wandb.ai/xmootoo/ssl-seizure-detection/runs/eyw68ffi' target=\"_blank\">https://wandb.ai/xmootoo/ssl-seizure-detection/runs/eyw68ffi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231210_233621-eyw68ffi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from train import train\n",
    "\n",
    "\n",
    "# Mac\n",
    "data_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/patient_pyg/jh101/supervised\"\n",
    "logdir = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/models/downstream\"\n",
    "model_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/models/jh101/model/temporal_shuffling.pth\"\n",
    "model_dict_path = \"/Users/xaviermootoo/Documents/Data/ssl-seizure-detection/models/jh101/model/temporal_shuffling_state_dict.pth\"\n",
    "\n",
    "# PC\n",
    "data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\jh101\\supervised\"\n",
    "logdir = r\"C:\\Users\\xmoot\\Desktop\\Models\\ssl-seizure-detection\\jh101\"\n",
    "model_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\test\\model\\temporal_shuffling.pth\"\n",
    "model_dict_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\test\\model\\temporal_shuffling_state_dict.pth\"\n",
    "\n",
    "\n",
    "# Arguments\n",
    "patient_id = \"dummy\"\n",
    "datetime_id = None\n",
    "run_type = \"all\"\n",
    "transfer_id = \"temporal_shuffling\"\n",
    "\n",
    "\n",
    "model_id1 = \"downstream1\"\n",
    "config1 = {\n",
    "        \"hidden_channels\": [64, 64, 32],\n",
    "        \"dropout\": 0.1,\n",
    "}\n",
    "\n",
    "\n",
    "model_id2 = \"downstream2\"\n",
    "config2 = {\n",
    "        \"hidden_channels\": 32,\n",
    "        \"dropout\": 0.1,\n",
    "}\n",
    "\n",
    "train(data_path, logdir, patient_id, epochs=2, config=config1, data_size=0.05, val_ratio=0.2, test_ratio=0.1, \n",
    "          batch_size=32, num_workers=4, lr=1e-3, weight_decay=1e-3, model_id=model_id1, timing=True, \n",
    "          classify=\"binary\", head=\"linear\", dropout=True, datetime_id=datetime_id, run_type=run_type, frozen=False,\n",
    "          model_path=model_path, model_dict_path=model_dict_path, transfer_id=transfer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VICRegT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy data for running inference. \n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def generate_dummy_data(num_entries):\n",
    "    graphs = []\n",
    "    for _ in range(num_entries):\n",
    "        A = [\n",
    "            np.ones((107, 107)),\n",
    "            np.random.rand(107, 107),\n",
    "            np.random.rand(107, 107),\n",
    "            np.random.rand(107, 107)\n",
    "        ]\n",
    "        NF = [\n",
    "            np.ones((107, 1)),\n",
    "            np.random.rand(107, 1),\n",
    "            np.random.rand(107, 8)\n",
    "        ]\n",
    "        EF = [\n",
    "            np.ones((107, 107, 1)),\n",
    "            np.random.rand(107, 107, 1),\n",
    "            np.random.rand(107, 107, 1),\n",
    "            np.random.rand(107, 107, 1)\n",
    "        ]\n",
    "        graph = [A, NF, EF]\n",
    "        graphs.append(graph)\n",
    "    return graphs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preictal_data = generate_dummy_data(200)\n",
    "    with open('/Users/dentira/anomaly-detection/ssl-based-model/ssl-seizure-detection/ssl_seizure_detection/dummy_data/supervised/preictal_data.pkl', 'wb') as f:\n",
    "        pickle.dump(preictal_data, f)\n",
    "\n",
    "    ictal_data = generate_dummy_data(200)\n",
    "    with open('/Users/dentira/anomaly-detection/ssl-based-model/ssl-seizure-detection/ssl_seizure_detection/dummy_data/supervised/ictal_data.pkl', 'wb') as f:\n",
    "        pickle.dump(ictal_data, f)\n",
    "\n",
    "    postictal_data = generate_dummy_data(200)\n",
    "    with open('/Users/dentira/anomaly-detection/ssl-based-model/ssl-seizure-detection/ssl_seizure_detection/dummy_data/supervised/postictal_data.pkl', 'wb') as f:\n",
    "        pickle.dump(postictal_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maku221bb\u001b[0m (\u001b[33maku221bb-indian-institute-of-technology-kanpur\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dentira/anomaly-detection/epilepsy-detection/ssl_seizure_detection/notebooks/models/wandb/run-20250202_124515-iesxafq2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aku221bb-indian-institute-of-technology-kanpur/Test_Bay/runs/iesxafq2' target=\"_blank\">dummy_supervised_None_all</a></strong> to <a href='https://wandb.ai/aku221bb-indian-institute-of-technology-kanpur/Test_Bay' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aku221bb-indian-institute-of-technology-kanpur/Test_Bay' target=\"_blank\">https://wandb.ai/aku221bb-indian-institute-of-technology-kanpur/Test_Bay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aku221bb-indian-institute-of-technology-kanpur/Test_Bay/runs/iesxafq2' target=\"_blank\">https://wandb.ai/aku221bb-indian-institute-of-technology-kanpur/Test_Bay/runs/iesxafq2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dentira/anomaly-detection/epilepsy-detection/ssl_seizure_detection/src/data/preprocess.py:730: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  all_runs.append(torch.load(os.path.join(logdir, run)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS Device Acceleration.\n",
      "Total number of examples in dataset: 92450.\n",
      "Total number of examples used: 92450.\n",
      "Number of training examples: 92450. Number of training batches: 2890.\n",
      "Total number of examples in dataset: 39622.\n",
      "Total number of examples used: 39622.\n",
      "Number of validation examples: 27735. Number of validation batches: 867.\n",
      "Number of test examples: 11886. Number of test batches: 372.\n",
      "Time elapsed after 100 batches (training): 85.53s\n",
      "Time elapsed after 100 batches (training): 2.92s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.93s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (evaluation): 15.20s\n",
      "Time elapsed after 100 batches (evaluation): 1.25s\n",
      "Time elapsed after 100 batches (evaluation): 1.25s\n",
      "Time elapsed after 100 batches (evaluation): 1.21s\n",
      "Epoch: 1, Train Loss: 0.06105299373415128, Train Accuracy: 97.91022174148188, Validation Loss: 25165.67717783938, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001002. New classifier lr: 0.019972\n",
      "Time elapsed after 100 batches (training): 83.90s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.52s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.49s\n",
      "Time elapsed after 100 batches (training): 2.53s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.94s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (evaluation): 14.23s\n",
      "Time elapsed after 100 batches (evaluation): 1.27s\n",
      "Time elapsed after 100 batches (evaluation): 1.24s\n",
      "Time elapsed after 100 batches (evaluation): 1.28s\n",
      "Epoch: 2, Train Loss: 0.04250806160287281, Train Accuracy: 98.47809626825311, Validation Loss: 8.410584993259882, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001006. New classifier lr: 0.019889\n",
      "Time elapsed after 100 batches (training): 77.63s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 3.49s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.75s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.90s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.75s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (evaluation): 13.98s\n",
      "Time elapsed after 100 batches (evaluation): 1.24s\n",
      "Time elapsed after 100 batches (evaluation): 1.23s\n",
      "Time elapsed after 100 batches (evaluation): 1.23s\n",
      "Epoch: 3, Train Loss: 0.04083956778440206, Train Accuracy: 98.53542455381287, Validation Loss: 26323.72633673555, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001014. New classifier lr: 0.019751\n",
      "Time elapsed after 100 batches (training): 77.96s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.75s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.84s\n",
      "Time elapsed after 100 batches (training): 2.83s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (evaluation): 15.48s\n",
      "Time elapsed after 100 batches (evaluation): 1.21s\n",
      "Time elapsed after 100 batches (evaluation): 1.20s\n",
      "Time elapsed after 100 batches (evaluation): 1.24s\n",
      "Epoch: 4, Train Loss: 0.039418389438570935, Train Accuracy: 98.59167117360735, Validation Loss: 2.4479199535744165, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001024. New classifier lr: 0.019560\n",
      "Time elapsed after 100 batches (training): 75.61s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.95s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.48s\n",
      "Time elapsed after 100 batches (training): 2.50s\n",
      "Time elapsed after 100 batches (training): 2.48s\n",
      "Time elapsed after 100 batches (training): 2.50s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.71s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.52s\n",
      "Time elapsed after 100 batches (training): 2.49s\n",
      "Time elapsed after 100 batches (training): 2.49s\n",
      "Time elapsed after 100 batches (training): 4.59s\n",
      "Time elapsed after 100 batches (training): 2.45s\n",
      "Time elapsed after 100 batches (evaluation): 14.28s\n",
      "Time elapsed after 100 batches (evaluation): 1.18s\n",
      "Time elapsed after 100 batches (evaluation): 1.19s\n",
      "Time elapsed after 100 batches (evaluation): 1.19s\n",
      "Epoch: 5, Train Loss: 0.0375356146134839, Train Accuracy: 98.66630611141157, Validation Loss: 46302.3479187668, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001038. New classifier lr: 0.019315\n",
      "Time elapsed after 100 batches (training): 74.68s\n",
      "Time elapsed after 100 batches (training): 2.52s\n",
      "Time elapsed after 100 batches (training): 2.48s\n",
      "Time elapsed after 100 batches (training): 2.84s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (evaluation): 15.21s\n",
      "Time elapsed after 100 batches (evaluation): 1.20s\n",
      "Time elapsed after 100 batches (evaluation): 1.19s\n",
      "Time elapsed after 100 batches (evaluation): 1.18s\n",
      "Epoch: 6, Train Loss: 0.03621994382105639, Train Accuracy: 98.70849107625743, Validation Loss: 2.049983797855275, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001054. New classifier lr: 0.019019\n",
      "Time elapsed after 100 batches (training): 77.49s\n",
      "Time elapsed after 100 batches (training): 2.48s\n",
      "Time elapsed after 100 batches (training): 2.42s\n",
      "Time elapsed after 100 batches (training): 2.44s\n",
      "Time elapsed after 100 batches (training): 2.47s\n",
      "Time elapsed after 100 batches (training): 2.44s\n",
      "Time elapsed after 100 batches (training): 2.46s\n",
      "Time elapsed after 100 batches (training): 2.42s\n",
      "Time elapsed after 100 batches (training): 2.45s\n",
      "Time elapsed after 100 batches (training): 2.45s\n",
      "Time elapsed after 100 batches (training): 2.49s\n",
      "Time elapsed after 100 batches (training): 2.46s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.47s\n",
      "Time elapsed after 100 batches (training): 2.46s\n",
      "Time elapsed after 100 batches (training): 2.49s\n",
      "Time elapsed after 100 batches (training): 2.50s\n",
      "Time elapsed after 100 batches (training): 2.48s\n",
      "Time elapsed after 100 batches (training): 2.49s\n",
      "Time elapsed after 100 batches (training): 2.49s\n",
      "Time elapsed after 100 batches (training): 2.53s\n",
      "Time elapsed after 100 batches (training): 2.46s\n",
      "Time elapsed after 100 batches (training): 2.47s\n",
      "Time elapsed after 100 batches (training): 2.52s\n",
      "Time elapsed after 100 batches (training): 2.48s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (evaluation): 14.17s\n",
      "Time elapsed after 100 batches (evaluation): 1.23s\n",
      "Time elapsed after 100 batches (evaluation): 1.22s\n",
      "Time elapsed after 100 batches (evaluation): 1.22s\n",
      "Epoch: 7, Train Loss: 0.03921595481002806, Train Accuracy: 98.60897782585181, Validation Loss: 3.0587272147337594, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001074. New classifier lr: 0.018674\n",
      "Time elapsed after 100 batches (training): 77.76s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.53s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 3.15s\n",
      "Time elapsed after 100 batches (training): 2.97s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.91s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.75s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (training): 2.93s\n",
      "Time elapsed after 100 batches (training): 2.95s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (evaluation): 13.96s\n",
      "Time elapsed after 100 batches (evaluation): 1.35s\n",
      "Time elapsed after 100 batches (evaluation): 1.32s\n",
      "Time elapsed after 100 batches (evaluation): 1.29s\n",
      "Epoch: 8, Train Loss: 0.12365226705915498, Train Accuracy: 96.65548945375879, Validation Loss: 8.319437585851198, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001095. New classifier lr: 0.018281\n",
      "Time elapsed after 100 batches (training): 79.96s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.84s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 2.93s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.94s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.90s\n",
      "Time elapsed after 100 batches (evaluation): 15.98s\n",
      "Time elapsed after 100 batches (evaluation): 1.29s\n",
      "Time elapsed after 100 batches (evaluation): 1.31s\n",
      "Time elapsed after 100 batches (evaluation): 1.28s\n",
      "Epoch: 9, Train Loss: 0.0672551567816082, Train Accuracy: 97.7836668469443, Validation Loss: 19202.957010248654, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001120. New classifier lr: 0.017844\n",
      "Time elapsed after 100 batches (training): 80.00s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.91s\n",
      "Time elapsed after 100 batches (training): 2.91s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.75s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.83s\n",
      "Time elapsed after 100 batches (training): 2.75s\n",
      "Time elapsed after 100 batches (training): 2.84s\n",
      "Time elapsed after 100 batches (training): 2.93s\n",
      "Time elapsed after 100 batches (training): 2.83s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.92s\n",
      "Time elapsed after 100 batches (training): 2.92s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (evaluation): 15.16s\n",
      "Time elapsed after 100 batches (evaluation): 1.25s\n",
      "Time elapsed after 100 batches (evaluation): 1.24s\n",
      "Time elapsed after 100 batches (evaluation): 1.27s\n",
      "Epoch: 10, Train Loss: 0.0449339995554658, Train Accuracy: 98.39480800432666, Validation Loss: 3.180353899796804, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001146. New classifier lr: 0.017364\n",
      "Time elapsed after 100 batches (training): 75.98s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.91s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.94s\n",
      "Time elapsed after 100 batches (training): 3.01s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (evaluation): 14.58s\n",
      "Time elapsed after 100 batches (evaluation): 1.32s\n",
      "Time elapsed after 100 batches (evaluation): 1.19s\n",
      "Time elapsed after 100 batches (evaluation): 1.29s\n",
      "Epoch: 11, Train Loss: 0.043025695422992984, Train Accuracy: 98.42184964845863, Validation Loss: 79854.92580225134, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001175. New classifier lr: 0.016845\n",
      "Time elapsed after 100 batches (training): 81.35s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.75s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.83s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.90s\n",
      "Time elapsed after 100 batches (training): 2.85s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (training): 5.25s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.92s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.75s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (evaluation): 13.80s\n",
      "Time elapsed after 100 batches (evaluation): 1.24s\n",
      "Time elapsed after 100 batches (evaluation): 1.22s\n",
      "Time elapsed after 100 batches (evaluation): 1.23s\n",
      "Epoch: 12, Train Loss: 0.04275288904161486, Train Accuracy: 98.45754461871282, Validation Loss: 23606.40369308636, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001206. New classifier lr: 0.016290\n",
      "Time elapsed after 100 batches (training): 78.53s\n",
      "Time elapsed after 100 batches (training): 3.71s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.90s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.75s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.71s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (evaluation): 15.25s\n",
      "Time elapsed after 100 batches (evaluation): 1.20s\n",
      "Time elapsed after 100 batches (evaluation): 1.23s\n",
      "Time elapsed after 100 batches (evaluation): 1.20s\n",
      "Epoch: 13, Train Loss: 0.04151823578134927, Train Accuracy: 98.47376960519199, Validation Loss: 1.3683865467707317, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001239. New classifier lr: 0.015702\n",
      "Time elapsed after 100 batches (training): 81.78s\n",
      "Time elapsed after 100 batches (training): 2.49s\n",
      "Time elapsed after 100 batches (training): 2.45s\n",
      "Time elapsed after 100 batches (training): 2.53s\n",
      "Time elapsed after 100 batches (training): 2.48s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.47s\n",
      "Time elapsed after 100 batches (training): 2.49s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.53s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.50s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.53s\n",
      "Time elapsed after 100 batches (evaluation): 14.03s\n",
      "Time elapsed after 100 batches (evaluation): 1.20s\n",
      "Time elapsed after 100 batches (evaluation): 1.19s\n",
      "Time elapsed after 100 batches (evaluation): 1.19s\n",
      "Epoch: 14, Train Loss: 0.04133929232901581, Train Accuracy: 98.50513791238507, Validation Loss: 76719.60840893818, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001273. New classifier lr: 0.015086\n",
      "Time elapsed after 100 batches (training): 81.31s\n",
      "Time elapsed after 100 batches (training): 2.48s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.53s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.52s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (evaluation): 13.97s\n",
      "Time elapsed after 100 batches (evaluation): 1.28s\n",
      "Time elapsed after 100 batches (evaluation): 1.30s\n",
      "Time elapsed after 100 batches (evaluation): 1.26s\n",
      "Epoch: 15, Train Loss: 0.041062000432498046, Train Accuracy: 98.53326122228232, Validation Loss: 31148.27963814684, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001309. New classifier lr: 0.014444\n",
      "Time elapsed after 100 batches (training): 80.98s\n",
      "Time elapsed after 100 batches (training): 2.97s\n",
      "Time elapsed after 100 batches (training): 3.01s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (evaluation): 14.46s\n",
      "Time elapsed after 100 batches (evaluation): 1.22s\n",
      "Time elapsed after 100 batches (evaluation): 1.19s\n",
      "Time elapsed after 100 batches (evaluation): 1.20s\n",
      "Epoch: 16, Train Loss: 0.041846297000201295, Train Accuracy: 98.47809626825311, Validation Loss: 0.7618545490887857, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001345. New classifier lr: 0.013781\n",
      "Time elapsed after 100 batches (training): 80.74s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.94s\n",
      "Time elapsed after 100 batches (training): 4.00s\n",
      "Time elapsed after 100 batches (training): 2.95s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 2.91s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (evaluation): 15.87s\n",
      "Time elapsed after 100 batches (evaluation): 1.24s\n",
      "Time elapsed after 100 batches (evaluation): 1.23s\n",
      "Time elapsed after 100 batches (evaluation): 1.22s\n",
      "Epoch: 17, Train Loss: 0.0425299065893719, Train Accuracy: 98.44023796646836, Validation Loss: 1.8883481397423694, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001383. New classifier lr: 0.013101\n",
      "Time elapsed after 100 batches (training): 85.48s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.83s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.85s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.85s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (evaluation): 14.63s\n",
      "Time elapsed after 100 batches (evaluation): 1.25s\n",
      "Time elapsed after 100 batches (evaluation): 1.29s\n",
      "Time elapsed after 100 batches (evaluation): 1.32s\n",
      "Epoch: 18, Train Loss: 0.04145593286131808, Train Accuracy: 98.47268793942672, Validation Loss: 33048.893391927086, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001422. New classifier lr: 0.012408\n",
      "Time elapsed after 100 batches (training): 80.90s\n",
      "Time elapsed after 100 batches (training): 2.85s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.49s\n",
      "Time elapsed after 100 batches (training): 2.47s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.53s\n",
      "Time elapsed after 100 batches (training): 960.07s\n",
      "Time elapsed after 100 batches (training): 3.15s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.50s\n",
      "Time elapsed after 100 batches (training): 3.21s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.53s\n",
      "Time elapsed after 100 batches (training): 2.50s\n",
      "Time elapsed after 100 batches (training): 2.45s\n",
      "Time elapsed after 100 batches (training): 2.44s\n",
      "Time elapsed after 100 batches (training): 2.46s\n",
      "Time elapsed after 100 batches (training): 2.46s\n",
      "Time elapsed after 100 batches (training): 935.33s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (evaluation): 13.39s\n",
      "Time elapsed after 100 batches (evaluation): 1.15s\n",
      "Time elapsed after 100 batches (evaluation): 1.14s\n",
      "Time elapsed after 100 batches (evaluation): 1.13s\n",
      "Epoch: 19, Train Loss: 0.04074770560613785, Train Accuracy: 98.53326122228232, Validation Loss: 0.5273521077889268, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001461. New classifier lr: 0.011706\n",
      "Time elapsed after 100 batches (training): 1929.94s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 273.44s\n",
      "Time elapsed after 100 batches (training): 3.03s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.71s\n",
      "Time elapsed after 100 batches (training): 2.75s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 3.10s\n",
      "Time elapsed after 100 batches (training): 3.04s\n",
      "Time elapsed after 100 batches (training): 3.01s\n",
      "Time elapsed after 100 batches (training): 2.96s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (evaluation): 14.13s\n",
      "Time elapsed after 100 batches (evaluation): 1.28s\n",
      "Time elapsed after 100 batches (evaluation): 1.27s\n",
      "Time elapsed after 100 batches (evaluation): 1.28s\n",
      "Epoch: 20, Train Loss: 0.03866229167983103, Train Accuracy: 98.61546782044348, Validation Loss: 521272.0025201613, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001500. New classifier lr: 0.011000\n",
      "Time elapsed after 100 batches (training): 84.10s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.95s\n",
      "Time elapsed after 100 batches (training): 2.95s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.52s\n",
      "Time elapsed after 100 batches (training): 2.54s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.71s\n",
      "Time elapsed after 100 batches (training): 2.71s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (evaluation): 13.90s\n",
      "Time elapsed after 100 batches (evaluation): 1.27s\n",
      "Time elapsed after 100 batches (evaluation): 1.30s\n",
      "Time elapsed after 100 batches (evaluation): 1.31s\n",
      "Epoch: 21, Train Loss: 0.04825191653327965, Train Accuracy: 98.34937804218497, Validation Loss: 3.397835501740056, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001539. New classifier lr: 0.010294\n",
      "Time elapsed after 100 batches (training): 83.78s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.85s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.83s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 3.08s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (evaluation): 14.12s\n",
      "Time elapsed after 100 batches (evaluation): 1.36s\n",
      "Time elapsed after 100 batches (evaluation): 1.29s\n",
      "Time elapsed after 100 batches (evaluation): 1.40s\n",
      "Epoch: 22, Train Loss: 0.04119109385143353, Train Accuracy: 98.48458626284479, Validation Loss: 3978.3452384702623, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001578. New classifier lr: 0.009592\n",
      "Time elapsed after 100 batches (training): 82.25s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.90s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.47s\n",
      "Time elapsed after 100 batches (training): 2.48s\n",
      "Time elapsed after 100 batches (training): 2.52s\n",
      "Time elapsed after 100 batches (training): 2.50s\n",
      "Time elapsed after 100 batches (training): 2.46s\n",
      "Time elapsed after 100 batches (training): 2.50s\n",
      "Time elapsed after 100 batches (training): 2.45s\n",
      "Time elapsed after 100 batches (training): 2.45s\n",
      "Time elapsed after 100 batches (training): 2.52s\n",
      "Time elapsed after 100 batches (training): 2.48s\n",
      "Time elapsed after 100 batches (training): 2.49s\n",
      "Time elapsed after 100 batches (training): 2.44s\n",
      "Time elapsed after 100 batches (training): 2.53s\n",
      "Time elapsed after 100 batches (training): 2.47s\n",
      "Time elapsed after 100 batches (training): 2.45s\n",
      "Time elapsed after 100 batches (training): 2.49s\n",
      "Time elapsed after 100 batches (training): 4.15s\n",
      "Time elapsed after 100 batches (training): 2.49s\n",
      "Time elapsed after 100 batches (training): 2.46s\n",
      "Time elapsed after 100 batches (training): 2.47s\n",
      "Time elapsed after 100 batches (training): 2.46s\n",
      "Time elapsed after 100 batches (evaluation): 14.68s\n",
      "Time elapsed after 100 batches (evaluation): 1.33s\n",
      "Time elapsed after 100 batches (evaluation): 1.27s\n",
      "Time elapsed after 100 batches (evaluation): 1.41s\n",
      "Epoch: 23, Train Loss: 0.039746633586175674, Train Accuracy: 98.57003785830179, Validation Loss: 3.6549117879201005, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001617. New classifier lr: 0.008899\n",
      "Time elapsed after 100 batches (training): 83.56s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.50s\n",
      "Time elapsed after 100 batches (training): 2.49s\n",
      "Time elapsed after 100 batches (training): 2.47s\n",
      "Time elapsed after 100 batches (training): 2.49s\n",
      "Time elapsed after 100 batches (training): 2.46s\n",
      "Time elapsed after 100 batches (training): 2.45s\n",
      "Time elapsed after 100 batches (training): 2.45s\n",
      "Time elapsed after 100 batches (training): 2.51s\n",
      "Time elapsed after 100 batches (training): 2.46s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.51s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.51s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.45s\n",
      "Time elapsed after 100 batches (evaluation): 13.80s\n",
      "Time elapsed after 100 batches (evaluation): 1.26s\n",
      "Time elapsed after 100 batches (evaluation): 1.32s\n",
      "Time elapsed after 100 batches (evaluation): 1.34s\n",
      "Epoch: 24, Train Loss: 0.04051556975011163, Train Accuracy: 98.53001622498648, Validation Loss: 5543.428687310988, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001655. New classifier lr: 0.008219\n",
      "Time elapsed after 100 batches (training): 82.82s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.52s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.99s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 3.52s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.51s\n",
      "Time elapsed after 100 batches (training): 2.50s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (evaluation): 14.60s\n",
      "Time elapsed after 100 batches (evaluation): 1.32s\n",
      "Time elapsed after 100 batches (evaluation): 1.34s\n",
      "Time elapsed after 100 batches (evaluation): 1.88s\n",
      "Epoch: 25, Train Loss: 0.0409628624050994, Train Accuracy: 98.5191995673337, Validation Loss: 5175.001942624328, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001691. New classifier lr: 0.007556\n",
      "Time elapsed after 100 batches (training): 84.45s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.51s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 3.44s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.83s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.84s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.52s\n",
      "Time elapsed after 100 batches (evaluation): 13.95s\n",
      "Time elapsed after 100 batches (evaluation): 1.21s\n",
      "Time elapsed after 100 batches (evaluation): 1.27s\n",
      "Time elapsed after 100 batches (evaluation): 1.30s\n",
      "Epoch: 26, Train Loss: 0.04047486436803854, Train Accuracy: 98.53542455381287, Validation Loss: 0.5965586177283718, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001727. New classifier lr: 0.006914\n",
      "Time elapsed after 100 batches (training): 84.49s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.71s\n",
      "Time elapsed after 100 batches (training): 2.85s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.83s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.71s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.85s\n",
      "Time elapsed after 100 batches (training): 2.91s\n",
      "Time elapsed after 100 batches (evaluation): 15.97s\n",
      "Time elapsed after 100 batches (evaluation): 1.34s\n",
      "Time elapsed after 100 batches (evaluation): 1.28s\n",
      "Time elapsed after 100 batches (evaluation): 1.33s\n",
      "Epoch: 27, Train Loss: 0.042203974553543404, Train Accuracy: 98.47268793942672, Validation Loss: 2.4519227252852533, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001761. New classifier lr: 0.006298\n",
      "Time elapsed after 100 batches (training): 83.05s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.90s\n",
      "Time elapsed after 100 batches (training): 4.55s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 2.85s\n",
      "Time elapsed after 100 batches (training): 3.00s\n",
      "Time elapsed after 100 batches (training): 3.36s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.71s\n",
      "Time elapsed after 100 batches (training): 3.01s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (evaluation): 14.01s\n",
      "Time elapsed after 100 batches (evaluation): 1.24s\n",
      "Time elapsed after 100 batches (evaluation): 1.28s\n",
      "Time elapsed after 100 batches (evaluation): 1.31s\n",
      "Epoch: 28, Train Loss: 0.05156366930570402, Train Accuracy: 98.21416982152515, Validation Loss: 3.405048240577021, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001794. New classifier lr: 0.005710\n",
      "Time elapsed after 100 batches (training): 86.28s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 3.07s\n",
      "Time elapsed after 100 batches (training): 3.08s\n",
      "Time elapsed after 100 batches (training): 3.05s\n",
      "Time elapsed after 100 batches (training): 3.04s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (evaluation): 13.76s\n",
      "Time elapsed after 100 batches (evaluation): 1.26s\n",
      "Time elapsed after 100 batches (evaluation): 1.25s\n",
      "Time elapsed after 100 batches (evaluation): 1.24s\n",
      "Epoch: 29, Train Loss: 0.04112702023478025, Train Accuracy: 98.49756625202812, Validation Loss: 2.912053858400673, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001825. New classifier lr: 0.005155\n",
      "Time elapsed after 100 batches (training): 83.74s\n",
      "Time elapsed after 100 batches (training): 2.75s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.71s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.90s\n",
      "Time elapsed after 100 batches (training): 2.92s\n",
      "Time elapsed after 100 batches (training): 3.10s\n",
      "Time elapsed after 100 batches (training): 3.13s\n",
      "Time elapsed after 100 batches (training): 3.09s\n",
      "Time elapsed after 100 batches (training): 3.09s\n",
      "Time elapsed after 100 batches (evaluation): 14.76s\n",
      "Time elapsed after 100 batches (evaluation): 1.18s\n",
      "Time elapsed after 100 batches (evaluation): 1.26s\n",
      "Time elapsed after 100 batches (evaluation): 1.37s\n",
      "Epoch: 30, Train Loss: 0.04107702611579002, Train Accuracy: 98.49107625743645, Validation Loss: 1.5607413686411356, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001854. New classifier lr: 0.004636\n",
      "Time elapsed after 100 batches (training): 82.83s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.94s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.85s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.71s\n",
      "Time elapsed after 100 batches (training): 2.84s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 3.02s\n",
      "Time elapsed after 100 batches (training): 3.07s\n",
      "Time elapsed after 100 batches (training): 2.97s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (evaluation): 14.14s\n",
      "Time elapsed after 100 batches (evaluation): 1.27s\n",
      "Time elapsed after 100 batches (evaluation): 1.21s\n",
      "Time elapsed after 100 batches (evaluation): 1.21s\n",
      "Epoch: 31, Train Loss: 0.04240573404749991, Train Accuracy: 98.46403461330449, Validation Loss: 2.8203400431140775, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001880. New classifier lr: 0.004156\n",
      "Time elapsed after 100 batches (training): 81.94s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.83s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (training): 2.92s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 2.92s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.71s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (training): 2.84s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 3.28s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.71s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.75s\n",
      "Time elapsed after 100 batches (evaluation): 14.52s\n",
      "Time elapsed after 100 batches (evaluation): 1.31s\n",
      "Time elapsed after 100 batches (evaluation): 1.29s\n",
      "Time elapsed after 100 batches (evaluation): 1.31s\n",
      "Epoch: 32, Train Loss: 0.04275565335368351, Train Accuracy: 98.42725797728502, Validation Loss: 8257.114927230343, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001905. New classifier lr: 0.003719\n",
      "Time elapsed after 100 batches (training): 83.77s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 3.39s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.55s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (evaluation): 14.62s\n",
      "Time elapsed after 100 batches (evaluation): 1.48s\n",
      "Time elapsed after 100 batches (evaluation): 1.35s\n",
      "Time elapsed after 100 batches (evaluation): 1.35s\n",
      "Epoch: 33, Train Loss: 0.04413196908557388, Train Accuracy: 98.39913466738778, Validation Loss: 1.985439319443959, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001926. New classifier lr: 0.003326\n",
      "Time elapsed after 100 batches (training): 85.15s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.90s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.93s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 3.00s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.98s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (training): 2.90s\n",
      "Time elapsed after 100 batches (training): 2.97s\n",
      "Time elapsed after 100 batches (training): 2.98s\n",
      "Time elapsed after 100 batches (training): 2.75s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (evaluation): 15.00s\n",
      "Time elapsed after 100 batches (evaluation): 1.31s\n",
      "Time elapsed after 100 batches (evaluation): 1.29s\n",
      "Time elapsed after 100 batches (evaluation): 1.32s\n",
      "Epoch: 34, Train Loss: 0.04233560307695817, Train Accuracy: 98.47052460789617, Validation Loss: 1.819319651652408, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001946. New classifier lr: 0.002981\n",
      "Time elapsed after 100 batches (training): 83.93s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.90s\n",
      "Time elapsed after 100 batches (training): 2.71s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.75s\n",
      "Time elapsed after 100 batches (training): 2.78s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.84s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.92s\n",
      "Time elapsed after 100 batches (training): 2.90s\n",
      "Time elapsed after 100 batches (training): 2.92s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 2.84s\n",
      "Time elapsed after 100 batches (training): 2.98s\n",
      "Time elapsed after 100 batches (training): 2.94s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 2.75s\n",
      "Time elapsed after 100 batches (training): 2.84s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.96s\n",
      "Time elapsed after 100 batches (training): 2.91s\n",
      "Time elapsed after 100 batches (training): 2.94s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (evaluation): 14.76s\n",
      "Time elapsed after 100 batches (evaluation): 1.40s\n",
      "Time elapsed after 100 batches (evaluation): 1.36s\n",
      "Time elapsed after 100 batches (evaluation): 1.29s\n",
      "Epoch: 35, Train Loss: 0.05968231306762586, Train Accuracy: 98.02704164413197, Validation Loss: 1.0148613188535935, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001962. New classifier lr: 0.002685\n",
      "Time elapsed after 100 batches (training): 85.09s\n",
      "Time elapsed after 100 batches (training): 2.95s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.85s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 2.97s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.58s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.56s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.71s\n",
      "Time elapsed after 100 batches (training): 2.96s\n",
      "Time elapsed after 100 batches (training): 3.16s\n",
      "Time elapsed after 100 batches (training): 3.50s\n",
      "Time elapsed after 100 batches (training): 3.42s\n",
      "Time elapsed after 100 batches (training): 3.01s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.96s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (evaluation): 14.63s\n",
      "Time elapsed after 100 batches (evaluation): 1.43s\n",
      "Time elapsed after 100 batches (evaluation): 1.52s\n",
      "Time elapsed after 100 batches (evaluation): 1.53s\n",
      "Epoch: 36, Train Loss: 0.04122240699974298, Train Accuracy: 98.47701460248783, Validation Loss: 77209.29322076614, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001976. New classifier lr: 0.002440\n",
      "Time elapsed after 100 batches (training): 83.73s\n",
      "Time elapsed after 100 batches (training): 3.29s\n",
      "Time elapsed after 100 batches (training): 3.25s\n",
      "Time elapsed after 100 batches (training): 3.33s\n",
      "Time elapsed after 100 batches (training): 2.90s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 3.16s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.68s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.70s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.66s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (evaluation): 15.43s\n",
      "Time elapsed after 100 batches (evaluation): 1.25s\n",
      "Time elapsed after 100 batches (evaluation): 1.53s\n",
      "Time elapsed after 100 batches (evaluation): 1.24s\n",
      "Epoch: 37, Train Loss: 0.04265809314052339, Train Accuracy: 98.46187128177394, Validation Loss: 4.4523523257624715, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001986. New classifier lr: 0.002249\n",
      "Time elapsed after 100 batches (training): 84.36s\n",
      "Time elapsed after 100 batches (training): 2.93s\n",
      "Time elapsed after 100 batches (training): 2.84s\n",
      "Time elapsed after 100 batches (training): 2.85s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.74s\n",
      "Time elapsed after 100 batches (training): 2.85s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.92s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 2.95s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 2.96s\n",
      "Time elapsed after 100 batches (training): 2.95s\n",
      "Time elapsed after 100 batches (training): 2.91s\n",
      "Time elapsed after 100 batches (training): 2.90s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 2.76s\n",
      "Time elapsed after 100 batches (training): 2.77s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.79s\n",
      "Time elapsed after 100 batches (training): 2.88s\n",
      "Time elapsed after 100 batches (training): 2.99s\n",
      "Time elapsed after 100 batches (training): 3.06s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (training): 2.89s\n",
      "Time elapsed after 100 batches (evaluation): 14.86s\n",
      "Time elapsed after 100 batches (evaluation): 1.34s\n",
      "Time elapsed after 100 batches (evaluation): 1.36s\n",
      "Time elapsed after 100 batches (evaluation): 1.35s\n",
      "Epoch: 38, Train Loss: 0.041428678734856415, Train Accuracy: 98.47809626825311, Validation Loss: 3.16579841125396, Validation Accuracy: 94.55662123506646\n",
      "New encoder lr: 0.001994. New classifier lr: 0.002111\n",
      "Time elapsed after 100 batches (training): 83.25s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.73s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 2.96s\n",
      "Time elapsed after 100 batches (training): 3.14s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 2.86s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 3.04s\n",
      "Time elapsed after 100 batches (training): 2.98s\n",
      "Time elapsed after 100 batches (training): 2.94s\n",
      "Time elapsed after 100 batches (training): 2.93s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.93s\n",
      "Time elapsed after 100 batches (training): 2.95s\n",
      "Time elapsed after 100 batches (training): 2.87s\n",
      "Time elapsed after 100 batches (training): 3.08s\n",
      "Time elapsed after 100 batches (training): 2.81s\n",
      "Time elapsed after 100 batches (training): 2.82s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 2.98s\n",
      "Time elapsed after 100 batches (training): 2.90s\n",
      "Time elapsed after 100 batches (training): 2.93s\n",
      "Time elapsed after 100 batches (training): 3.16s\n",
      "Time elapsed after 100 batches (training): 3.26s\n",
      "Time elapsed after 100 batches (training): 2.92s\n",
      "Time elapsed after 100 batches (training): 2.98s\n",
      "Time elapsed after 100 batches (evaluation): 15.67s\n",
      "Time elapsed after 100 batches (evaluation): 1.29s\n",
      "Time elapsed after 100 batches (evaluation): 1.27s\n",
      "Time elapsed after 100 batches (evaluation): 1.32s\n",
      "Epoch: 39, Train Loss: 0.04175031285053828, Train Accuracy: 98.46727961060033, Validation Loss: 3323.7940739457326, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.001998. New classifier lr: 0.002028\n",
      "Time elapsed after 100 batches (training): 82.62s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 3.36s\n",
      "Time elapsed after 100 batches (training): 2.57s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.69s\n",
      "Time elapsed after 100 batches (training): 2.59s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.65s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.60s\n",
      "Time elapsed after 100 batches (training): 2.63s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.72s\n",
      "Time elapsed after 100 batches (training): 2.80s\n",
      "Time elapsed after 100 batches (training): 2.71s\n",
      "Time elapsed after 100 batches (training): 2.83s\n",
      "Time elapsed after 100 batches (training): 2.67s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.61s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.62s\n",
      "Time elapsed after 100 batches (training): 2.64s\n",
      "Time elapsed after 100 batches (evaluation): 15.84s\n",
      "Time elapsed after 100 batches (evaluation): 1.23s\n",
      "Time elapsed after 100 batches (evaluation): 1.23s\n",
      "Time elapsed after 100 batches (evaluation): 1.23s\n",
      "Epoch: 40, Train Loss: 0.04243804281182703, Train Accuracy: 98.4586262844781, Validation Loss: 2921.9684120096185, Validation Accuracy: 5.443378764933535\n",
      "New encoder lr: 0.002000. New classifier lr: 0.002000\n",
      "Time elapsed after 100 batches (evaluation): 28.01s\n",
      "Time elapsed after 100 batches (evaluation): 1.42s\n",
      "Time elapsed after 100 batches (evaluation): 1.36s\n",
      "Time elapsed after 100 batches (evaluation): 1.41s\n",
      "Time elapsed after 100 batches (evaluation): 1.30s\n",
      "Time elapsed after 100 batches (evaluation): 1.34s\n",
      "Time elapsed after 100 batches (evaluation): 1.40s\n",
      "Time elapsed after 100 batches (evaluation): 1.45s\n",
      "Time elapsed after 100 batches (evaluation): 1.37s\n",
      "Training complete. Test Loss: 2925.5048602851066. Test Accuracy: 5.318190012619434.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'total_examples'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 52\u001b[0m\n\u001b[1;32m     22\u001b[0m loss_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     24\u001b[0m train_config \u001b[38;5;241m=\u001b[39m TrainConfig(\n\u001b[1;32m     25\u001b[0m     train_path\u001b[38;5;241m=\u001b[39mtrain_path,\n\u001b[1;32m     26\u001b[0m     test_path\u001b[38;5;241m=\u001b[39mtest_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     classify\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m )\n\u001b[0;32m---> 52\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anomaly-detection/epilepsy-detection/ssl_seizure_detection/src/train/train.py:140\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config, model_config, loss_config)\u001b[0m\n\u001b[1;32m    137\u001b[0m save_stats(train_loss, val_loss, train_acc, val_acc, stats_dir)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m#<----------Save Training Information---------->\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m info_dict \u001b[38;5;241m=\u001b[39m \u001b[43mget_wandb_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mtest_ratio\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    143\u001b[0m     info_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest examples\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m loader_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_examples\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anomaly-detection/epilepsy-detection/ssl_seizure_detection/src/train/utils.py:379\u001b[0m, in \u001b[0;36mget_wandb_info\u001b[0;34m(config, model_config, loss_config, loader_stats)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_wandb_info\u001b[39m(config, model_config, loss_config, loader_stats):\n\u001b[1;32m    369\u001b[0m         info_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    370\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatient ID\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mpatient_id,\n\u001b[1;32m    371\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel ID\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mmodel_id,\n\u001b[1;32m    372\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer ID\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mtransfer_id,\n\u001b[1;32m    373\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperiment ID\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mexp_id,\n\u001b[1;32m    374\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassify\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mclassify,\n\u001b[1;32m    375\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrozen (Encoder)\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrequires_grad,\n\u001b[1;32m    376\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredictive Head\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mhead,\n\u001b[1;32m    377\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate & Time\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mdatetime_id,\n\u001b[1;32m    378\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData size\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mdata_size,\n\u001b[0;32m--> 379\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal examples\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mloader_stats\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtotal_examples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m    380\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsed examples\u001b[39m\u001b[38;5;124m'\u001b[39m: loader_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused_examples\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining examples\u001b[39m\u001b[38;5;124m'\u001b[39m: loader_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_examples\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m    382\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation examples\u001b[39m\u001b[38;5;124m'\u001b[39m: loader_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_examples\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    383\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining batches\u001b[39m\u001b[38;5;124m'\u001b[39m: loader_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_batches\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    384\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation batches\u001b[39m\u001b[38;5;124m'\u001b[39m: loader_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_batches\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    385\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mval_ratio,\n\u001b[1;32m    386\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mtest_ratio,\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mtrain_ratio,\n\u001b[1;32m    388\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch size\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m    389\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of workers\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mnum_workers,\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearning rate\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mlr,\n\u001b[1;32m    391\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight decay\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mweight_decay,\n\u001b[1;32m    392\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of epochs\u001b[39m\u001b[38;5;124m'\u001b[39m: config\u001b[38;5;241m.\u001b[39mepochs,\n\u001b[1;32m    393\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel parameters\u001b[39m\u001b[38;5;124m'\u001b[39m: config,\n\u001b[1;32m    394\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDropout\u001b[39m\u001b[38;5;124m'\u001b[39m: model_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    395\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDropout Probability\u001b[39m\u001b[38;5;124m'\u001b[39m:  model_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    396\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss Config\u001b[39m\u001b[38;5;124m'\u001b[39m: loss_config,\n\u001b[1;32m    397\u001b[0m         }\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m info_dict\n",
      "\u001b[0;31mKeyError\u001b[0m: 'total_examples'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/dentira/anomaly-detection/epilepsy-detection/ssl_seizure_detection/src/train')\n",
    "sys.path.append('/Users/dentira/anomaly-detection/epilepsy-detection/ssl_seizure_detection/src/config')\n",
    "from train import train\n",
    "from config import ModelConfig, LossConfig, TrainConfig\n",
    "# Linux\n",
    "train_path = \"/Users/dentira/anomaly-detection/epilepsy-detection/ssl_seizure_detection/data/patient_gr_train\"\n",
    "test_path = \"/Users/dentira/anomaly-detection/epilepsy-detection/ssl_seizure_detection/data/patient_gr_test\"\n",
    "logdir = \"/Users/dentira/anomaly-detection/epilepsy-detection/ssl_seizure_detection/1.0\"\n",
    "\n",
    "model_config = {\n",
    "    \"num_node_features\":9,\n",
    "    \"num_edge_features\":3,\n",
    "    \"hidden_channels\":[32, 16, 16],\n",
    "    \"batch_norm\":True,\n",
    "    \"classify\":\"binary\",\n",
    "    \"head\" : \"linear\",\n",
    "    \"dropout\": True,\n",
    "    \"p\": 0.1\n",
    "}\n",
    "\n",
    "loss_config = None\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    data_path=train_path,\n",
    "    logdir=logdir,\n",
    "    patient_id=\"dummy\",\n",
    "    epochs=40,\n",
    "    train_ratio=1.0,\n",
    "    val_ratio=0.7,\n",
    "    test_ratio=0.3,\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    lr=[1e-3, 0.02],\n",
    "    weight_decay=1e-3,\n",
    "    model_id=\"supervised\",\n",
    "    timing=True,\n",
    "    project_id=\"Test_Bay\",\n",
    "    patience=20,\n",
    "    eta_min=0.002,\n",
    "    run_type=\"all\",\n",
    "    exp_id= \"dummy_1\",\n",
    "    datetime_id=None,\n",
    "    requires_grad=True,\n",
    "    head=\"linear\",\n",
    "    classify= \"binary\"\n",
    ")\n",
    "\n",
    "\n",
    "train(train_config, model_config, loss_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downstream3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'data_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Model parameters\u001b[39;00m\n\u001b[1;32m     14\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassify\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m---> 16\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatient_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdummy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdownstream3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtiming\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m          \u001b[49m\u001b[43mclassify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassify\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhead\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatetime_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dict_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_dict_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransfer_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVICRegT1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m          \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTest_Bay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.002\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'data_path'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../src')\n",
    "from train import train\n",
    "\n",
    "# PC\n",
    "data_path = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\jh101\\supervised\"\n",
    "logdir = r\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\test\"\n",
    "transfer_id = \"VICRegT1\"\n",
    "model_path = rf\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\test\\model\\{transfer_id}.pth\"\n",
    "model_dict_path = rf\"C:\\Users\\xmoot\\Desktop\\Data\\ssl-seizure-detection\\patient_pyg\\test\\model\\{transfer_id}_state_dict.pth\"\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "config = {\"classify\": \"binary\", \"head\": \"linear\"}\n",
    "\n",
    "train(data_path=data_path, logdir=logdir, patient_id=\"dummy\", epochs=30, config=config, data_size=0.1, val_ratio=0.2, test_ratio=0.1, \n",
    "          batch_size=32, num_workers=4, lr=[1e-3, 0.02], weight_decay=1e-3, model_id=\"downstream3\", timing=True, \n",
    "          classify=config[\"classify\"], head=config[\"head\"], dropout=False, datetime_id=None, run_type=\"all\", requires_grad=True,\n",
    "          model_path=model_path, model_dict_path=model_dict_path, transfer_id=\"VICRegT1\", train_ratio=None, loss_config=None,\n",
    "          project_id=\"Test_Bay\", patience = 20, eta_min=0.002)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
