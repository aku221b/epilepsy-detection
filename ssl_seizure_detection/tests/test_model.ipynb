{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Relative Positioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models import relative_positioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node features of shape (num_nodes, num_node_features) and type torch.float32\n",
    "from torch_geometric.loader import DataLoader\n",
    "from preprocess import PairData\n",
    "\n",
    "x1 = torch.tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                    [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                    [2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "                    [3, 3, 3, 3, 3, 3, 3, 3, 3]], dtype=torch.float32)\n",
    "x2 = torch.tensor([[4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "                    [5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
    "                    [6, 6, 6, 6, 6, 6, 6, 6, 6]], dtype=torch.float32)\n",
    "\n",
    "# Edge indices of shape (2, num_edges) and type torch.long\n",
    "edge_index1 = torch.tensor([[0, 1, 1, 2, 2, 3],\n",
    "                             [1, 0, 2, 1, 3, 2]], dtype=torch.long)\n",
    "edge_index2 = torch.tensor([[0, 1, 1, 2],\n",
    "                             [1, 0, 2, 1]], dtype=torch.long)\n",
    "\n",
    "# Edge features of shape (num_edges, num_edge_features) and type torch.float32\n",
    "edge_attr1 = torch.tensor([[0, 0, 0],\n",
    "                            [1,1,1],\n",
    "                            [2,2,2],\n",
    "                            [3,3,3],\n",
    "                            [4,4,4],\n",
    "                            [5,5,5]], dtype=torch.float32)\n",
    "edge_attr2 = torch.tensor([[6,6,6],\n",
    "                            [7,7,7],\n",
    "                            [8,8,8],\n",
    "                            [9,9,9]], dtype=torch.float32)\n",
    "\n",
    "# Pair label of shape (1,) and type torch.long\n",
    "y = torch.tensor([1], dtype=torch.float32)\n",
    "\n",
    "data = PairData(x1=x1, edge_index1=edge_index1, edge_attr1=edge_attr1,  # Graph 1.\n",
    "                x2=x2, edge_index2=edge_index2, edge_attr2=edge_attr2,  # Graph 2.\n",
    "                y=y) #Graph pair label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [data, data, data, data]\n",
    "dataloader = DataLoader(data_list, batch_size=2, follow_batch=['x1', 'x2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.248107671737671\n",
      "0.33536654710769653\n"
     ]
    }
   ],
   "source": [
    "model = relative_positioning(num_node_features=9, num_edge_features=3, hidden_channels=[64, 128], out_channels=32)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "for batch in dataloader:\n",
    "    # Move batch data to the device\n",
    "    batch.x1 = batch.x1.to(device)\n",
    "    batch.edge_index1 = batch.edge_index1.to(device)\n",
    "    batch.edge_attr1 = batch.edge_attr1.to(device)\n",
    "    batch.x1_batch = batch.x1_batch.to(device)\n",
    "    \n",
    "    batch.x2 = batch.x2.to(device)\n",
    "    batch.edge_index2 = batch.edge_index2.to(device)\n",
    "    batch.edge_attr2 = batch.edge_attr2.to(device)\n",
    "    batch.x2_batch = batch.x2_batch.to(device)\n",
    "    \n",
    "    batch.y = batch.y.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out = model(batch.x1, batch.edge_index1, batch.edge_attr1, batch.x1_batch,\n",
    "                batch.x2, batch.edge_index2, batch.edge_attr2, batch.x2_batch)\n",
    "    loss = criterion(out, batch.y)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Temporal Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import TripletData\n",
    "\n",
    "# Node features of shape (num_nodes, num_node_features) and type torch.float32\n",
    "from torch_geometric.loader import DataLoader\n",
    "from preprocess import PairData\n",
    "\n",
    "x1 = torch.tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                    [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                    [2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "                    [3, 3, 3, 3, 3, 3, 3, 3, 3]], dtype=torch.float32)\n",
    "x2 = torch.tensor([[4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
    "                    [5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
    "                    [6, 6, 6, 6, 6, 6, 6, 6, 6]], dtype=torch.float32)\n",
    "\n",
    "# Edge indices of shape (2, num_edges) and type torch.long\n",
    "edge_index1 = torch.tensor([[0, 1, 1, 2, 2, 3],\n",
    "                             [1, 0, 2, 1, 3, 2]], dtype=torch.long)\n",
    "edge_index2 = torch.tensor([[0, 1, 1, 2],\n",
    "                             [1, 0, 2, 1]], dtype=torch.long)\n",
    "\n",
    "# Edge features of shape (num_edges, num_edge_features) and type torch.float32\n",
    "edge_attr1 = torch.tensor([[0, 0, 0],\n",
    "                            [1,1,1],\n",
    "                            [2,2,2],\n",
    "                            [3,3,3],\n",
    "                            [4,4,4],\n",
    "                            [5,5,5]], dtype=torch.float32)\n",
    "edge_attr2 = torch.tensor([[6,6,6],\n",
    "                            [7,7,7],\n",
    "                            [8,8,8],\n",
    "                            [9,9,9]], dtype=torch.float32)\n",
    "\n",
    "# Pair label of shape (1,) and type torch.long\n",
    "y = torch.tensor([1], dtype=torch.float32)\n",
    "\n",
    "data = TripletData(x1=x1, edge_index1=edge_index1, edge_attr1=edge_attr1,  # Graph 1.\n",
    "                x2=x2, edge_index2=edge_index2, edge_attr2=edge_attr2,  # Graph 2.\n",
    "                x3=x2, edge_index3=edge_index2, edge_attr3=edge_attr2,  # Graph 2.\n",
    "                y=y) #Graph pair label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [data,data,data,data]\n",
    "dataloader = DataLoader(data_list, batch_size=2, follow_batch=['x1', 'x2', 'x3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6862651109695435\n",
      "0.3853457570075989\n"
     ]
    }
   ],
   "source": [
    "from models import temporal_shuffling\n",
    "model = temporal_shuffling(num_node_features=9, num_edge_features=3, hidden_channels=[32, 64], out_channels=32)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "for batch in dataloader:\n",
    "    # Move batch data to the device\n",
    "    batch.x1 = batch.x1.to(device)\n",
    "    batch.edge_index1 = batch.edge_index1.to(device)\n",
    "    batch.edge_attr1 = batch.edge_attr1.to(device)\n",
    "    batch.x1_batch = batch.x1_batch.to(device)\n",
    "    \n",
    "    batch.x2 = batch.x2.to(device)\n",
    "    batch.edge_index2 = batch.edge_index2.to(device)\n",
    "    batch.edge_attr2 = batch.edge_attr2.to(device)\n",
    "    batch.x2_batch = batch.x2_batch.to(device)\n",
    "\n",
    "    batch.x3 = batch.x3.to(device)\n",
    "    batch.edge_index3 = batch.edge_index3.to(device)\n",
    "    batch.edge_attr3 = batch.edge_attr3.to(device)\n",
    "    batch.x3_batch = batch.x3_batch.to(device)\n",
    "    \n",
    "    batch.y = batch.y.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out = model(batch.x1, batch.edge_index1, batch.edge_attr1, batch.x1_batch,\n",
    "                batch.x2, batch.edge_index2, batch.edge_attr2, batch.x2_batch,\n",
    "                batch.x3, batch.edge_index3, batch.edge_attr3, batch.x3_batch)\n",
    "    loss = criterion(out, batch.y)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2_mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
